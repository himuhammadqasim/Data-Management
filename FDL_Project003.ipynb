{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "cell_execution_strategy": "setup",
      "private_outputs": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himuhammadqasim/Data-Management/blob/main/FDL_Project003.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Model architectures and training phase\n",
        "This section deals with the models creation, the performance results and the dicussion of them.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s2QnN7tuNKAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy opencv-python matplotlib"
      ],
      "metadata": {
        "id": "MjH_OdItqXCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "SHKm14iYl9o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NaRGpFrPqxd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OCHOnB8MtFYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers, models\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "zgUk7mzuszxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "zDaMhtaOsguw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "PYPiCsv3NTrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tBy2e_3WQNOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"http://download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "metadata": {
        "id": "U_duE__QrwV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roses = list(data_dir.glob('roses/*'))\n",
        "PIL.Image.open(str(roses[0]))"
      ],
      "metadata": {
        "id": "0Yq_z8t7rwYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir"
      ],
      "metadata": {
        "id": "CEKGZdlorwbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1CqxT6hLrwer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copyfile('gdrive/My Drive/Deep Learning Project/Crack.zip', 'Crack.zip')"
      ],
      "metadata": {
        "id": "KZiM8Ag2nC2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define the path to the zip file in Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/flower_photos.tgz'  # Replace with your actual path"
      ],
      "metadata": {
        "id": "0aeGiIl0ap3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Unzip the .tgz file\n",
        "import tarfile"
      ],
      "metadata": {
        "id": "jqto8AwQap5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the .tgz file using tarfile\n",
        "with tarfile.open(zip_file_path, 'r:gz') as tar:\n",
        "    # Extract all contents to the desired directory (e.g., \"/content/\")\n",
        "    tar.extractall('/content/')"
      ],
      "metadata": {
        "id": "FwI9jazWap8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qdfhvOKxxVHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Define the directory path where the images are stored\n",
        "#data_dir = '/content/flower_photos/'  # Change this to the actual path\n",
        "\n",
        "# List all image files in the directory\n",
        "image_files = os.listdir(data_dir) #image_dir\n",
        "\n"
      ],
      "metadata": {
        "id": "sliCuYK0ap_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_files"
      ],
      "metadata": {
        "id": "jHPiQsKGaqCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NmgTsAKkaqQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ENjAGdjyjy-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Define the directory path where the images are stored\n",
        "#image_dir = '/content/flower_photos/'  # Change this to the actual path\n",
        "\n",
        "# Use glob to get a list of all image file paths in the 'photos' folder and its subfolders\n",
        "image_file_paths = glob.glob(os.path.join(data_dir, '**', '*.jpg'), recursive=True)\n",
        "# Change '*.jpg' to the appropriate file extension if your images have a different format.\n",
        "\n",
        "# Load images into a list\n",
        "images = []\n",
        "for file_path in image_file_paths:\n",
        "    with Image.open(file_path) as img:\n",
        "        images.append(img.copy())  # Use img.copy() to prevent issues with the context manager\n",
        "\n",
        "# Now the images list contains all the images properly loaded and closed.\n"
      ],
      "metadata": {
        "id": "bQIBDWF_jzDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images"
      ],
      "metadata": {
        "id": "z33nd-UpjzGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"
      ],
      "metadata": {
        "id": "LFEySppPj0C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting IMages, Labels, and class names from the directory folder"
      ],
      "metadata": {
        "id": "iqh-bPQKNZT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Define the directory path where the images are stored\n",
        "#image_dir = '/content/flower_photos/'  # Change this to the actual path\n",
        "\n",
        "# Load and preprocess the image data\n",
        "def preprocess_images(folder_path, image_size=(128,128)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = []\n",
        "\n",
        "    for class_name in os.listdir(folder_path):\n",
        "        class_folder = os.path.join(folder_path, class_name)\n",
        "        if os.path.isdir(class_folder):\n",
        "            for image_file in os.listdir(class_folder):\n",
        "                image_path = os.path.join(class_folder, image_file)\n",
        "                img = Image.open(image_path)\n",
        "                img = img.resize(image_size)\n",
        "                img_array = np.array(img)\n",
        "                images.append(img_array)\n",
        "                labels.append(class_name)\n",
        "                if class_name not in class_names:\n",
        "                    class_names.append(class_name)\n",
        "\n",
        "    # Convert the labels to numerical values using LabelEncoder\n",
        "    label_encoder = LabelEncoder()\n",
        "    Y = label_encoder.fit_transform(labels)\n",
        "    y = np.array(Y)\n",
        "\n",
        "    # Convert the list of images to a NumPy array\n",
        "    X = np.array(images)\n",
        "\n",
        "    return X, y, class_names\n",
        "\n",
        "# Load and preprocess the images and labels\n",
        "X, y, class_names = preprocess_images(data_dir)\n",
        "\n",
        "# Verify the shape of X and Y\n",
        "print(\"Shape of X:\", X.shape)  # (num_samples, 224, 242, 3) for RGB images\n",
        "print(\"Shape of Y:\", y.shape)  # (num_samples,) representing the labels as numerical values\n",
        "print(\"Class names:\", class_names)  # List of class names (folder names)\n",
        "\n",
        "# Now, you can use X and Y as input data and target data for your model.\n",
        "# The images have been resized to 224x224, and Y contains the labels represented as numerical values.\n"
      ],
      "metadata": {
        "id": "1eftsatAj0N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PFdimZfZ5ZYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lkc5pK837-s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ac587SLw7-wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1OrRxA8c7-z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing of data"
      ],
      "metadata": {
        "id": "LeSOMLAOj0RA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=X/255        # scaling of each image pixel"
      ],
      "metadata": {
        "id": "xj4uYkmGj0Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hhfwMt4j9ipR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Now, you can use the augmented training and validation datasets in your model training\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have your data loaded in 'x' and 'Y'\n",
        "# Split the data into training, validation, and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=0)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=0)\n",
        "\n",
        "# Create a Sequential model for data augmentation\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=x_train.shape[1:]),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
        "    layers.experimental.preprocessing.RandomContrast(0.2),\n",
        "     layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "])\n",
        "\n",
        "# Create TensorFlow datasets for training, validation, and testing\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "# Add a batch dimension to the input data before applying data augmentation\n",
        "train_dataset = train_dataset.map(lambda x, y: (tf.expand_dims(x, 0), y))\n",
        "validation_dataset = validation_dataset.map(lambda x, y: (tf.expand_dims(x, 0), y))\n",
        "\n",
        "# Apply data augmentation to the training dataset\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(x_train))\n",
        "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "train_dataset = train_dataset.batch(batch_size=16)\n",
        "\n",
        "# Apply data augmentation to the validation dataset (optional)\n",
        "validation_dataset = validation_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "validation_dataset = validation_dataset.batch(batch_size=16)\n",
        "\n",
        "# Now, you can use the augmented training and validation datasets in your model training\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "GEpRRF3lepv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have already created the augmented training dataset as 'train_dataset'\n",
        "\n",
        "# Extract a batch of augmented images from the dataset\n",
        "for batch in train_dataset.take(1):\n",
        "    augmented_images = batch[0]  # First element in the batch is the augmented images\n",
        "    original_labels = batch[1]   # Second element in the batch is the corresponding labels\n",
        "\n",
        "# Convert the random indices to a TensorFlow tensor\n",
        "num_images_to_visualize = 5\n",
        "random_indices = np.random.choice(len(augmented_images), num_images_to_visualize, replace=False)\n",
        "random_indices_tensor = tf.constant(random_indices)\n",
        "\n",
        "# Select the images at the random indices for visualization\n",
        "selected_images = tf.gather(augmented_images, random_indices_tensor)\n",
        "\n",
        "# Create a grid to visualize the images\n",
        "fig, axes = plt.subplots(1, num_images_to_visualize, figsize=(15, 3))\n",
        "\n",
        "# Plot the images\n",
        "for i, image in enumerate(selected_images):\n",
        "    image = tf.squeeze(image)  # Remove the batch dimension (squeeze)\n",
        "    image = (image.numpy() * 255).astype(np.uint8)  # Scale the image back to [0, 255]\n",
        "    axes[i].imshow(image)\n",
        "    axes[i].set_title(f\"Augmented Image {i+1}\")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tpADZS1a8hjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 1"
      ],
      "metadata": {
        "id": "8OfEycJaDuKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "model = keras.Sequential([\n",
        "    data_augmentation,  # Include data augmentation as the first layer\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=x_train.shape[1:]),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),  # Dropout layer to reduce overfitting\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer= keras.optimizers.Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "282AFFIZ-Daw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "8fQ61GhvKT4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a generator function for training data\n",
        "def data_generator(x_train, y_train, batch_size):\n",
        "    num_samples = len(x_train)\n",
        "    indices = np.arange(num_samples)\n",
        "\n",
        "    while True:\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for i in range(0, num_samples, batch_size):\n",
        "            batch_indices = indices[i:i + batch_size]\n",
        "            batch_x = x_train[batch_indices]\n",
        "            batch_y = y_train[batch_indices]\n",
        "            yield batch_x, batch_y\n",
        "\n",
        "# Define batch size and create the data generator\n",
        "batch_size = 16\n",
        "train_generator = data_generator(x_train, y_train, batch_size)\n",
        "\n",
        "# Fit the model using the data generator and include validation data\n",
        "steps_per_epoch = len(x_train) // batch_size\n",
        "validation_dataset = (x_val, y_val)  # Use the validation data you already have\n",
        "\n",
        "model.fit(train_generator, epochs=10, steps_per_epoch=steps_per_epoch, validation_data=validation_dataset)\n"
      ],
      "metadata": {
        "id": "7XvH83E0-Ds4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have already trained the model using the code provided earlier\n",
        "\n",
        "# Get the training history from the model\n",
        "history = model.history.history\n",
        "\n",
        "# Plot training and validation loss over epochs\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history['loss'], label='Training Loss')\n",
        "plt.plot(history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy over epochs\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "n8isi9uzqWr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already trained the model and have x_test and y_test ready\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "9mSBnZQ9-Duh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming you have already trained the model and have x_test ready\n",
        "\n",
        "# Get some randomly chosen indices from the test dataset\n",
        "num_images_to_predict = 5\n",
        "random_indices = np.random.choice(len(x_test), num_images_to_predict, replace=False)\n",
        "selected_images = x_test[random_indices]\n",
        "\n",
        "# Make predictions on the selected images\n",
        "predictions = model.predict(selected_images)\n",
        "\n",
        "# Convert predictions to class labels (if you have a classification problem)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Display the predictions\n",
        "for i in range(num_images_to_predict):\n",
        "    print(f\"Image {i+1}:\")\n",
        "    print(f\"True Label: {y_test[random_indices[i]]}\")\n",
        "    print(f\"Predicted Class: {predicted_classes[i]}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "X1Bzt0wh-Dwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have already trained the model and have x_test, y_test, and predicted_classes ready\n",
        "\n",
        "# Get some randomly chosen indices from the test dataset\n",
        "num_images_to_predict = 5\n",
        "random_indices = np.random.choice(len(x_test), num_images_to_predict, replace=False)\n",
        "selected_images = x_test[random_indices]\n",
        "true_labels = y_test[random_indices]\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Create a mapping for class labels (if applicable)\n",
        "\n",
        "# Display the images with true and predicted labels\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(num_images_to_predict):\n",
        "    plt.subplot(1, num_images_to_predict, i + 1)\n",
        "    plt.imshow(selected_images[i])\n",
        "    plt.title(f\"True: {class_names[true_labels[i]]}\\nPredicted: {class_names[predicted_classes[i]]}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8_XB9iZV-Dy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming you have already trained the model and have x_test, y_test, and predicted_classes ready\n",
        "\n",
        "# Make predictions on the test dataset using the trained Keras model\n",
        "predictions = model.predict(x_test)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Print the classification report\n",
        " # Replace with your class names\n",
        "print(classification_report(y_test, predicted_classes, target_names=class_names))\n"
      ],
      "metadata": {
        "id": "AyT4mMX1dZSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EqVLNc5Uj0b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model with regularization, Batch normalization and double Dense layer"
      ],
      "metadata": {
        "id": "jXaGPbTzErsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "num_classes = 5\n",
        "model2 = keras.Sequential([\n",
        "    data_augmentation,  # Include data augmentation as the first layer\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=x_train.shape[1:], padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model2.compile(optimizer= keras.optimizers.Adam(learning_rate=0.0001),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "6RIhS4quEtCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RQhe1c7tMxS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "id": "hDNJrVrNEtPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a generator function for training data\n",
        "def data_generator(x_train, y_train, batch_size):\n",
        "    num_samples = len(x_train)\n",
        "    indices = np.arange(num_samples)\n",
        "\n",
        "    while True:\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for i in range(0, num_samples, batch_size):\n",
        "            batch_indices = indices[i:i + batch_size]\n",
        "            batch_x = x_train[batch_indices]\n",
        "            batch_y = y_train[batch_indices]\n",
        "            yield batch_x, batch_y\n",
        "\n",
        "# Define batch size and create the data generator\n",
        "batch_size = 16\n",
        "train_generator = data_generator(x_train, y_train, batch_size)\n",
        "\n",
        "# Fit the model using the data generator and include validation data\n",
        "steps_per_epoch = len(x_train) // batch_size\n",
        "validation_dataset = (x_val, y_val)  # Use the validation data you already have\n",
        "\n",
        "model2.fit(train_generator, epochs=10, steps_per_epoch=steps_per_epoch, validation_data=validation_dataset)\n"
      ],
      "metadata": {
        "id": "lYe6Q-bQEtR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3eVsD-9yEtUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "model3 = keras.Sequential([\n",
        "    data_augmentation,\n",
        "    layers.Conv2D(64, 7, padding=\"same\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "\n",
        "    layers.Conv2D(64, 3, padding=\"same\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "\n",
        "    # Note the explicit import of Conv2D from keras.layers\n",
        "    keras.layers.Conv2D(64, 3, padding=\"same\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "\n",
        "    layers.MaxPooling2D(3, strides=1, padding=\"same\"),\n",
        "    layers.Conv2D(64, 3, padding=\"same\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.Conv2D(64, 3, padding=\"same\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "\n",
        "    layers.Conv2D(64, 3, activation=\"relu\"),\n",
        "    layers.GlobalMaxPooling2D(),\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model3.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "ynSUp0luEtZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.summary()"
      ],
      "metadata": {
        "id": "4_GlrWXWTY38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a generator function for training data\n",
        "def data_generator(x_train, y_train, batch_size):\n",
        "    num_samples = len(x_train)\n",
        "    indices = np.arange(num_samples)\n",
        "\n",
        "    while True:\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for i in range(0, num_samples, batch_size):\n",
        "            batch_indices = indices[i:i + batch_size]\n",
        "            batch_x = x_train[batch_indices]\n",
        "            batch_y = y_train[batch_indices]\n",
        "            yield batch_x, batch_y\n",
        "\n",
        "# Define batch size and create the data generator\n",
        "batch_size = 16\n",
        "train_generator = data_generator(x_train, y_train, batch_size)\n",
        "\n",
        "# Fit the model using the data generator and include validation data\n",
        "steps_per_epoch = len(x_train) // batch_size\n",
        "validation_dataset = (x_val, y_val)  # Use the validation data you already have\n",
        "\n",
        "model3.fit(train_generator, epochs=10, steps_per_epoch=steps_per_epoch, validation_data=validation_dataset)\n"
      ],
      "metadata": {
        "id": "H8bbPe8pEtW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have already trained the model using the code provided earlier\n",
        "\n",
        "# Get the training history from the model\n",
        "history = model3.history.history\n",
        "\n",
        "# Plot training and validation loss over epochs\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history['loss'], label='Training Loss')\n",
        "plt.plot(history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy over epochs\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Tvhod72fEtcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "num_classes = 5\n",
        "model4 = keras.Sequential([\n",
        "data_augmentation,\n",
        "\n",
        "layers.Conv2D(32, 3, padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "layers.BatchNormalization(),\n",
        "layers.Activation(\"relu\"),\n",
        "layers.MaxPooling2D(3, strides=3, padding=\"same\"),\n",
        "\n",
        "layers.Conv2D(64, 3, padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "layers.BatchNormalization(),\n",
        "layers.Activation(\"relu\"),\n",
        "layers.MaxPooling2D(3, strides=3, padding=\"same\"),\n",
        "\n",
        "layers.Conv2D(128, 3, padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "layers.BatchNormalization(),\n",
        "layers.Activation(\"relu\"),\n",
        "layers.MaxPooling2D(3, strides=3, padding=\"same\"),\n",
        "\n",
        "layers.Conv2D(128, 3, padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "layers.BatchNormalization(),\n",
        "layers.Activation(\"relu\"),\n",
        "layers.MaxPooling2D(3, strides=3, padding=\"same\"),\n",
        "\n",
        "layers.Conv2D(512, 3, padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "\n",
        "layers.BatchNormalization(),\n",
        "layers.Activation(\"relu\"),\n",
        "layers.GlobalMaxPooling2D(),\n",
        "\n",
        "# ADD FLATTEN LAYER\n",
        "layers.Flatten(),\n",
        "# ADD DROPOUT LAYER\n",
        "layers.Dropout(.15),\n",
        "\n",
        "layers.Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "\n",
        "layers.Dense(num_classes, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2(0.001))])\n",
        "\n",
        "\n",
        "# PRINT THE SUMMARY\n",
        "model4.summary()\n",
        "\n",
        "\n",
        "model4.compile(optimizer= keras.optimizers.Adam(learning_rate=0.0001),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M1LoWyL9EtfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a generator function for training data\n",
        "def data_generator(x_train, y_train, batch_size):\n",
        "    num_samples = len(x_train)\n",
        "    indices = np.arange(num_samples)\n",
        "\n",
        "    while True:\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for i in range(0, num_samples, batch_size):\n",
        "            batch_indices = indices[i:i + batch_size]\n",
        "            batch_x = x_train[batch_indices]\n",
        "            batch_y = y_train[batch_indices]\n",
        "            yield batch_x, batch_y\n",
        "\n",
        "# Define batch size and create the data generator\n",
        "batch_size = 16\n",
        "train_generator = data_generator(x_train, y_train, batch_size)\n",
        "\n",
        "# Fit the model using the data generator and include validation data\n",
        "steps_per_epoch = len(x_train) // batch_size\n",
        "validation_dataset = (x_val, y_val)  # Use the validation data you already have\n",
        "\n",
        "model4.fit(train_generator, epochs=10, steps_per_epoch=steps_per_epoch, validation_data=validation_dataset)\n"
      ],
      "metadata": {
        "id": "XVeMQdR9EthQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have already trained the model using the code provided earlier\n",
        "\n",
        "# Get the training history from the model\n",
        "history = model4.history.history\n",
        "\n",
        "# Plot training and validation loss over epochs\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history['loss'], label='Training Loss')\n",
        "plt.plot(history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy over epochs\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0o0TMYEQEtkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LOucP4R7Etnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O03fuFx3EtqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "THU5yTpbEttu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### CNN MOdel VGG 19"
      ],
      "metadata": {
        "id": "jHxMLaZvzatR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already loaded and preprocessed 'X' and 'Y' as input data and target data\n",
        "# X should be a NumPy array containing the resized images (num_samples, 180, 180, 3)\n",
        "# Y should be a NumPy array containing the labels of flower categories (num_samples,)\n"
      ],
      "metadata": {
        "id": "YF-Aw8tSzaw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.applications import VGG19\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import SparseCategoricalCrossentropy\n"
      ],
      "metadata": {
        "id": "nJLrYayGF1V-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the VGG19 model (excluding the fully connected layers at the top)\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(180, 180, 3))\n",
        "\n",
        "# Add custom layers on top of VGG19\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(len(class_names), activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the layers in the base VGG19 model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "gLuXNKE1za0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "dttFNlpWza5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "AutJOc_Yza8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### NOT applied YET\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have your data loaded in 'x' and 'Y'\n",
        "# Split the data into training, validation, and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=0)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=0)\n",
        "\n",
        "# Create a Sequential model for data augmentation\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=x_train.shape[1:]),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
        "    #layers.experimental.preprocessing.RandomContrast(0.2),\n",
        "    #layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "])\n",
        "\n",
        "# Create TensorFlow datasets for training, validation, and testing\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "# Add a batch dimension to the input data before applying data augmentation\n",
        "train_dataset = train_dataset.map(lambda x, y: (tf.expand_dims(x, 0), y))\n",
        "validation_dataset = validation_dataset.map(lambda x, y: (tf.expand_dims(x, 0), y))\n",
        "\n",
        "# Apply data augmentation to the training dataset\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(x_train))\n",
        "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "train_dataset = train_dataset.batch(batch_size=16)\n",
        "\n",
        "# Apply data augmentation to the validation dataset (optional)\n",
        "validation_dataset = validation_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "validation_dataset = validation_dataset.batch(batch_size=16)\n",
        "\n",
        "# Now, you can use the augmented training and validation datasets in your model training\n"
      ],
      "metadata": {
        "id": "GvVhaoR8za_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "onzTttyTzbBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6VKLR_QCzbEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AyQ3UTL_zbHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8yA6HBuLzbJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r9NgdLdrzbMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0kV2xbGEzbPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h4x8hSUWj0fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xBJ-qmvKj0ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5B9Oox_7j0ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sLKs32tBj0nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fsiPOlkgDo2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EYtpdCHBDo41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HanD1_sSDo7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M3BFFKChDo-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JXsbazC5DpBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzRyq_XHDpDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VJaYuoNrDpGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QOVaOXFADpJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1rx3okE3DpL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6E5RKJmPDpOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cDSXDLrZDpRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iLpcVcsVDpUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PasfdmNVDpWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p6mb81o-DpZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B5xcOuAeDpcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"
      ],
      "metadata": {
        "id": "FvbByUDhj0o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "JpSNZi_IinIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "IDLwME7DaqHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tf.config.experimental.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "id": "ea5V_k5HaqKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "  tf.config.experimental.set_memory_growth(gpu,True)"
      ],
      "metadata": {
        "id": "caHStEQraqNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"
      ],
      "metadata": {
        "id": "_XmmYi_XaqQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nDh10U6EaqTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JMvYeNYLaqV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SHfd5fAeaqZX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}